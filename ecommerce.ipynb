{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hLkOmEO6D3m"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "print(sys.executable)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install plotly\n"
      ],
      "metadata": {
        "id": "-XnHZ5Hk6FL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import datetime, nltk, warnings\n",
        "import matplotlib.cm as cm\n",
        "import itertools\n",
        "\n",
        "\n",
        "from pathlib import Path\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "from sklearn import preprocessing, model_selection, metrics, feature_selection\n",
        "from sklearn.model_selection import GridSearchCV, learning_curve\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import neighbors, linear_model, svm, tree, ensemble\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.decomposition import PCA\n",
        "from IPython.display import display, HTML\n",
        "# import plotly.plotly as py\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "from plotly.offline import init_notebook_mode,iplot\n",
        "init_notebook_mode(connected=True)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.rcParams[\"patch.force_edgecolor\"] = True\n",
        "plt.style.use('fivethirtyeight')\n",
        "mpl.rc('patch', edgecolor = 'dimgray', linewidth=1)\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Av4eztfy6JDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_init = pd.read_csv('data.csv',encoding=\"ISO-8859-1\", dtype={'CustomerID': str,'InvoiceID': str})\n",
        "print('Dataframe dimensions:', df_init.shape)\n"
      ],
      "metadata": {
        "id": "-3nu8C4m6MFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_init.head(5)"
      ],
      "metadata": {
        "id": "69rATP0e6Ovn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_init.dtypes"
      ],
      "metadata": {
        "id": "IThAMDkn6Rkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_init.isnull().sum()"
      ],
      "metadata": {
        "id": "-eBGWVB96Utb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_init.shape[0]"
      ],
      "metadata": {
        "id": "MmnalWXt6X4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_init['InvoiceDate'] = pd.to_datetime(df_init['InvoiceDate'])\n",
        "\n",
        "# Get some infos on columns types and numer of null values\n",
        "\n",
        "# Using the different columns transpose the datatypes of each column as its respective row/value \n",
        "# To enable us get more intuition about the data type\n",
        "col_info = pd.DataFrame(df_init.dtypes).T.rename(index={0:'column type'}) \n",
        "\n",
        "# Sum the null values of each variable, transpose them(row name (null values (nb))) and append them to the col_info dataframe\n",
        "col_info = col_info.append(pd.DataFrame(df_init.isnull().sum()).T.rename(index={0:'null values (nb)'}))\n",
        "\n",
        "# Divide the sum null values by the total number of rows of our dataset, transpose and append to the col_info dataframe\n",
        "# This will give us the percentage value of missing data from that column/variable\n",
        "col_info = col_info.append(pd.DataFrame(df_init.isnull().sum()/df_init.shape[0]*100).T.rename\n",
        "                           (index={0:'null values (%)'}))\n"
      ],
      "metadata": {
        "id": "ywUCwuMX6bFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(col_info)"
      ],
      "metadata": {
        "id": "_DwtbBxN6ds6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_init[:5])"
      ],
      "metadata": {
        "id": "Z-WyQJ9v6gXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_init.dropna(axis = 0, subset = ['CustomerID'], inplace = True)\n",
        "print('Dataframe dimensions:', df_init.shape)\n"
      ],
      "metadata": {
        "id": "IsnoJRlW6ifc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_info = pd.DataFrame(df_init.dtypes).T.rename(index={0:'column type'})\n",
        "col_info = col_info.append(pd.DataFrame(df_init.isnull().sum()).T.rename(index={0:'null values (nb)'}))\n",
        "\n",
        "col_info = col_info.append(pd.DataFrame(df_init.isnull().sum()/df_init.shape[0]*100).T.\n",
        "                           rename(index={0:'null values (%)'}))\n",
        "display(col_info)\n"
      ],
      "metadata": {
        "id": "gurrK8Ou6lQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_init.dtypes"
      ],
      "metadata": {
        "id": "HOsr4dEV6oBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_init.isnull().sum()"
      ],
      "metadata": {
        "id": "pc_PzjZ16qXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_init['Country'].duplicated().value_counts()"
      ],
      "metadata": {
        "id": "327FdJT46tCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_init['InvoiceNo'].duplicated().value_counts()\n"
      ],
      "metadata": {
        "id": "-0oKU2WG6vo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Duplicate Entries: {}'.format(df_init.duplicated().sum()))\n",
        "df_init.drop_duplicates(inplace = True)\n"
      ],
      "metadata": {
        "id": "8Scn2edS6xkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the data set after droping duplicate entries :\", format(df_init.shape))"
      ],
      "metadata": {
        "id": "CmL5zsoE6znE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_cou = df_init[['CustomerID', 'InvoiceNo', 'Country']].groupby(['CustomerID', 'InvoiceNo', 'Country']).count()"
      ],
      "metadata": {
        "id": "z4j0JfPw62Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_cou\n"
      ],
      "metadata": {
        "id": "wIZfZMVa65ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_cou = temp_cou.reset_index(drop = False)"
      ],
      "metadata": {
        "id": "Q-WrMOUW67S1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_cou"
      ],
      "metadata": {
        "id": "y6n6jgmO6-Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "countries = temp_cou['Country'].value_counts()\n",
        "print('No. of countries in the dataframe: {}'.format(len(countries)))"
      ],
      "metadata": {
        "id": "fdFNmS9p7AIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "countries.index"
      ],
      "metadata": {
        "id": "lG-yTrZs7Djm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = dict(type='choropleth', \n",
        "            locations = countries.index,\n",
        "            locationmode = 'country names', z = countries,\n",
        "            text = countries.index, colorbar = {'title':'Order no.'},\n",
        "            colorscale=[[0, 'rgb(224,255,255)'],\n",
        "            [0.01, 'rgb(166,206,227)'], [0.02, 'rgb(31,120,180)'],\n",
        "            [0.03, 'rgb(178,223,138)'], [0.05, 'rgb(51,160,44)'],\n",
        "            [0.10, 'rgb(251,154,153)'], [0.20, 'rgb(255,255,0)'],\n",
        "            [1, 'rgb(227,26,28)']],    \n",
        "            reversescale = False)"
      ],
      "metadata": {
        "id": "G6cmsHGJ7GNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layout = dict(title='Number of orders per country',\n",
        "              geo = dict(showframe = True, projection={'type':'mercator'}))\n",
        "\n",
        "choromap = go.Figure(data = [data], layout = layout)\n",
        "iplot(choromap, validate=False)"
      ],
      "metadata": {
        "id": "bd9Zu26B7JXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_init\n"
      ],
      "metadata": {
        "id": "d2M6Hv8D7Lid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_init['CustomerID'].value_counts())"
      ],
      "metadata": {
        "id": "38SzL2457OMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame([{'products': len(df_init['StockCode'].value_counts()),    \n",
        "               'transactions': len(df_init['InvoiceNo'].value_counts()),\n",
        "               'customers': len(df_init['CustomerID'].value_counts()),}], \n",
        "             columns = ['products', 'transactions', 'customers'], index = ['quantity'])"
      ],
      "metadata": {
        "id": "1fKMx7on7QL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_pro = df_init.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['InvoiceDate'].count()\n",
        "\n",
        "# Rename the InvoiceDate to number of products\n",
        "nb_products_per_basket = temp_pro.rename(columns = {'InvoiceDate':'Number of products'})\n",
        "\n",
        "# Sort in Ascending order based on CustomerID\n",
        "nb_products_per_basket[:10].sort_values('CustomerID') # List first 10 values\n"
      ],
      "metadata": {
        "id": "01bhOv4O7Sru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_products_per_basket['order_canceled'] = nb_products_per_basket['InvoiceNo'].apply(lambda x:int('C' in x)) \n",
        "display(nb_products_per_basket[:5])\n",
        "\n",
        "# Sum total of order_canceled\n",
        "n1 = nb_products_per_basket['order_canceled'].sum()\n",
        "\n",
        "# Sum of rows\n",
        "n2 = nb_products_per_basket.shape[0]\n",
        "\n",
        "# Divide by 100 to get the percentage value\n",
        "print('Number of orders canceled: {}/{} ({:.2f}%) '.format(n1, n2, n1/n2*100))"
      ],
      "metadata": {
        "id": "h5CtgDRL7VuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_init.sort_values('CustomerID')[:5])"
      ],
      "metadata": {
        "id": "5MIXHBXr7Zz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_check = df_init[df_init['Quantity'] < 0][['CustomerID','Quantity','StockCode','Description','UnitPrice']]\n",
        "\n",
        "# Iterate through the rows, check if there is an order indicating same quantity(but positive), with same description(CustomerID\n",
        "# , Description, and UnitPrice)\n",
        "for index, col in  df_check.iterrows():\n",
        "    if df_init[(df_init['CustomerID'] == col[0]) & (df_init['Quantity'] == -col[1]) \n",
        "                & (df_init['Description'] == col[2])].shape[0] == 0: \n",
        "        print(df_check.loc[index])\n",
        "        print(15*'-'+'>'+' HYPOTHESIS NOT FULFILLED')\n",
        "        break"
      ],
      "metadata": {
        "id": "luUWfrDX7cgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_check = df_init[df_init['Quantity'] < 0][['CustomerID','Quantity','StockCode','Description','UnitPrice']]\n",
        "df_check\n"
      ],
      "metadata": {
        "id": "DO5OUlw37em5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_check = df_init[(df_init['Quantity'] < 0) & (df_init['Description'] != 'Discount')][['CustomerID','Quantity','StockCode',\n",
        "                                  'Description','UnitPrice']]\n",
        "\n",
        "for index, col in  df_check.iterrows():\n",
        "    if df_init[(df_init['CustomerID'] == col[0]) & (df_init['Quantity'] == -col[1]) & \n",
        "               (df_init['Description'] == col[2])].shape[0] == 0: \n",
        "        print(index, df_check.loc[index])\n",
        "        print(15*'-'+'>'+' HYPOTHESIS NOT FULFILLED')\n",
        "        break\n",
        "\n"
      ],
      "metadata": {
        "id": "cL7vuLFP7hq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned = df_init.copy(deep = True)  # made a deep copy of our dataset\n",
        "df_cleaned['QuantityCanceled'] = 0      # initialize the new varaible in the dataframe\n",
        "\n",
        "# \n",
        "entry_to_remove = [] ; doubtfull_entry = []\n",
        "\n",
        "\n",
        "for index, col in  df_init.iterrows():\n",
        "    if (col['Quantity'] > 0) or col['Description'] == 'Discount': continue        \n",
        "    df_test = df_init[(df_init['CustomerID'] == col['CustomerID']) &\n",
        "                         (df_init['StockCode']  == col['StockCode']) & \n",
        "                         (df_init['InvoiceDate'] < col['InvoiceDate']) & \n",
        "                         (df_init['Quantity']   > 0)].copy()\n",
        "    \n",
        "    # Cancelation WITHOUT counterpart\n",
        "    if (df_test.shape[0] == 0): \n",
        "        doubtfull_entry.append(index)\n",
        "        \n",
        "    # Cancelation WITH a counterpart\n",
        "    elif (df_test.shape[0] == 1): \n",
        "        index_order = df_test.index[0]\n",
        "        df_cleaned.loc[index_order, 'QuantityCanceled'] = -col['Quantity']\n",
        "        entry_to_remove.append(index) \n",
        "        \n",
        "    # Various counterparts exist in orders: we delete the last one\n",
        "    elif (df_test.shape[0] > 1): \n",
        "        df_test.sort_index(axis=0 ,ascending=False, inplace = True)        \n",
        "        for ind, val in df_test.iterrows():\n",
        "            if val['Quantity'] < -col['Quantity']: continue\n",
        "            df_cleaned.loc[ind, 'QuantityCanceled'] = -col['Quantity']\n",
        "            entry_to_remove.append(index) \n",
        "            break "
      ],
      "metadata": {
        "id": "TI9aQ3me7iXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"entry_to_remove: {}\".format(len(entry_to_remove)))\n",
        "print(\"doubtfull_entry: {}\".format(len(doubtfull_entry)))"
      ],
      "metadata": {
        "id": "vqJdGv0v7lUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.drop(entry_to_remove, axis = 0, inplace = True)\n",
        "df_cleaned.drop(doubtfull_entry, axis = 0, inplace = True)"
      ],
      "metadata": {
        "id": "PLwHVD0P7oLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_entries = df_cleaned[(df_cleaned['Quantity'] < 0) & (df_cleaned['StockCode'] != 'D')]\n",
        "print(\"nb of entries to delete: {}\".format(remaining_entries.shape[0]))\n",
        "remaining_entries.head(5)"
      ],
      "metadata": {
        "id": "axzBlQV-7rAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_entries.sort_index(axis=0)[:5]\n"
      ],
      "metadata": {
        "id": "zHBoIFMn7tGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.head(5)"
      ],
      "metadata": {
        "id": "F8T09cWW7vtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned.info()\n"
      ],
      "metadata": {
        "id": "Tvc4yUkV7yio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_special_codes = df_cleaned[df_cleaned['StockCode'].str.contains('^[a-zA-Z]+', regex=True)]['StockCode'].unique()\n",
        "list_special_codes\n"
      ],
      "metadata": {
        "id": "RIMI3aLB70cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for code in list_special_codes:\n",
        "    print(\"{:<15} -> {:<30}\".format(code, df_cleaned[df_cleaned['StockCode'] == code]['Description'].unique()[0]))"
      ],
      "metadata": {
        "id": "TLR2ilAs73JA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['TotalPrice'] = df_cleaned['UnitPrice'] * (df_cleaned['Quantity'] - df_cleaned['QuantityCanceled'])\n",
        "df_cleaned.sort_values('CustomerID')[:5]\n"
      ],
      "metadata": {
        "id": "WBLUZndu75UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_cleaned['InvoiceDate_int'] = df_cleaned['InvoiceDate'].astype('int64')\n",
        "df_cleaned[:5]\n"
      ],
      "metadata": {
        "id": "Aub5mdbj78A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_sum = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['TotalPrice'].sum()\n",
        "basket_price = temp_sum.rename(columns = {'TotalPrice':'Basket Price'})\n",
        "\n",
        "# date of the order\n",
        "df_cleaned['InvoiceDate_int'] = df_cleaned['InvoiceDate'].astype('int64')\n",
        "temp_date = df_cleaned.groupby(by=['CustomerID', 'InvoiceNo'], as_index=False)['InvoiceDate_int'].mean()\n",
        "df_cleaned.drop('InvoiceDate_int', axis = 1, inplace = True)\n",
        "basket_price.loc[:, 'InvoiceDate'] = pd.to_datetime(temp_date['InvoiceDate_int'])\n",
        "\n",
        "# selection of significant entries:\n",
        "basket_price = basket_price[basket_price['Basket Price'] > 0]\n",
        "basket_price.sort_values('CustomerID')[:6]\n"
      ],
      "metadata": {
        "id": "o-BKKGzr7-ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_range = [0, 50, 100, 200, 500, 1000, 5000, 50000]\n",
        "\n",
        "count_price = []\n",
        "\n",
        "for i, price in enumerate(price_range):\n",
        "    if i == 0: continue\n",
        "    val = basket_price[(basket_price['Basket Price'] < price) &\n",
        "                       (basket_price['Basket Price'] > price_range[i-1])]['Basket Price'].count()\n",
        "    count_price.append(val)\n",
        "    \n",
        "\n",
        "\n",
        "# Representation of the number of purchases / amount    \n",
        "plt.rc('font', weight='bold')\n",
        "f, ax = plt.subplots(figsize=(11, 6))\n",
        "colors = ['yellowgreen', 'gold', 'wheat', 'c', 'violet', 'royalblue','firebrick']\n",
        "labels = [ '{}<.<{}'.format(price_range[i-1], s) for i,s in enumerate(price_range) if i != 0]\n",
        "sizes  = count_price\n",
        "explode = [0.0 if sizes[i] < 100 else 0.0 for i in range(len(sizes))]\n",
        "ax.pie(sizes, explode = explode, labels=labels, colors = colors,\n",
        "       autopct = lambda x:'{:1.0f}%'.format(x) if x > 1 else '',\n",
        "       shadow = False, startangle=0)\n",
        "ax.axis('equal')\n",
        "f.text(0.5, 1.01, \"Distribution of order amounts\", ha='center', fontsize = 18);\n"
      ],
      "metadata": {
        "id": "3TwUENft8BAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_noun = lambda pos: pos[:2] == 'NN'\n",
        "\n",
        "def keywords_inventory(dataframe, colonne = 'Description'):\n",
        "    stemmer = nltk.stem.SnowballStemmer(\"english\")  # NLTK stemmer (Snowball stemmer)\n",
        "    keywords_roots  = dict()  # collect the words / root\n",
        "    keywords_select = dict()  # association: root <-> keyword\n",
        "    category_keys   = []\n",
        "    count_keywords  = dict()\n",
        "    icount = 0\n",
        "    for s in dataframe[colonne]:\n",
        "        if pd.isnull(s): continue\n",
        "        lines = s.lower()\n",
        "        tokenized = nltk.word_tokenize(lines)\n",
        "        nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)] \n",
        "        \n",
        "        for t in nouns:\n",
        "            t = t.lower() ; racine = stemmer.stem(t)\n",
        "            if racine in keywords_roots:                \n",
        "                keywords_roots[racine].add(t)\n",
        "                count_keywords[racine] += 1                \n",
        "            else:\n",
        "                keywords_roots[racine] = {t}\n",
        "                count_keywords[racine] = 1\n",
        "                \n",
        "    for s in keywords_roots.keys():\n",
        "        if len(keywords_roots[s]) > 1:  \n",
        "            min_length = 1000\n",
        "            for k in keywords_roots[s]:\n",
        "                if len(k) < min_length:\n",
        "                    clef = k ; min_length = len(k)            \n",
        "            category_keys.append(clef)\n",
        "            keywords_select[s] = clef\n",
        "        else:\n",
        "            category_keys.append(list(keywords_roots[s])[0])\n",
        "            keywords_select[s] = list(keywords_roots[s])[0]\n",
        "            \n",
        "            \n",
        "    print(\"No. of keywords in variable '{}': {}\".format(colonne,len(category_keys)))\n",
        "    return category_keys, keywords_roots, keywords_select, count_keywords"
      ],
      "metadata": {
        "id": "ByJm0Vtw8EGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liste = sorted(list_products, key = lambda x:x[1], reverse = True)\n",
        "\n",
        "\n",
        "plt.rc('font', weight='normal')\n",
        "fig, ax = plt.subplots(figsize=(10, 30))\n",
        "y_axis = [i[1] for i in liste[:125]]\n",
        "x_axis = [k for k,i in enumerate(liste[:125])]\n",
        "x_label = [i[0] for i in liste[:125]]\n",
        "plt.xticks(fontsize = 15)\n",
        "plt.yticks(fontsize = 13)\n",
        "plt.yticks(x_axis, x_label)\n",
        "plt.xlabel(\"No. of occurences\", fontsize = 18, labelpad = 10)\n",
        "ax.barh(x_axis, y_axis, align = 'center')\n",
        "ax = plt.gca()\n",
        "ax.invert_yaxis()\n",
        "\n",
        "\n",
        "plt.title(\"Words occurence\",bbox={'facecolor':'k', 'pad':5}, color='w',fontsize = 25)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cxv613Ah8HFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_products = []\n",
        "\n",
        "\n",
        "# Loop through the count_keywords and check the different conditions\n",
        "for k,v in count_keywords.items():\n",
        "    word = keywords_select[k]\n",
        "    if word in ['pink', 'blue', 'tag', 'green', 'orange']: continue\n",
        "    if len(word) < 3 or v < 13: continue\n",
        "    if ('+' in word) or ('/' in word): continue\n",
        "    list_products.append([word, v])\n",
        "    \n",
        "\n",
        "# list most kept words\n",
        "list_products.sort(key = lambda x:x[1], reverse = True)\n",
        "print('words kept:', len(list_products))\n"
      ],
      "metadata": {
        "id": "nHenTz5D8KoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "liste_produits = df_cleaned['Description'].unique()\n",
        "X = pd.DataFrame()\n",
        "for key, occurence in list_products:\n",
        "    X.loc[:, key] = list(map(lambda x:int(key.upper() in x), liste_produits))\n",
        "\n",
        "threshold = [0, 1, 2, 3, 5, 10]\n",
        "label_col = []\n",
        "\n",
        "for i in range(len(threshold)):\n",
        "    if i == len(threshold)-1:\n",
        "        col = '.>{}'.format(threshold[i])\n",
        "    else:\n",
        "        col = '{}<.<{}'.format(threshold[i],threshold[i+1])\n",
        "    label_col.append(col)\n",
        "    X.loc[:, col] = 0\n",
        "\n",
        "for i, prod in enumerate(liste_produits):\n",
        "    prix = df_cleaned[df_cleaned['Description'] == prod]['UnitPrice'].mean()\n",
        "    j = 0\n",
        "    while prix > threshold[j]:\n",
        "        j+=1\n",
        "        if j == len(threshold): break\n",
        "    X.loc[i, label_col[j-1]] = 1\n",
        "\n",
        "\n",
        "     "
      ],
      "metadata": {
        "id": "ZZwtKYXf8N_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"{:<8} {:<20} \\n\".format('range', 'no. products') + 20*'-')\n",
        "\n",
        "for i in range(len(threshold)):\n",
        "    if i == len(threshold)-1:\n",
        "        col = '.>{}'.format(threshold[i])\n",
        "    else:\n",
        "        col = '{}<.<{}'.format(threshold[i],threshold[i+1])    \n",
        "    print(\"{:<10}  {:<20}\".format(col, X.loc[:, col].sum()))\n"
      ],
      "metadata": {
        "id": "79UphLpV8Ta6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8t35Xzfp8WAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EJ_42Foj8OFp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}